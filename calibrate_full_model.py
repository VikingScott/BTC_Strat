import pandas as pd
import numpy as np
import os
from scipy import stats

# ==========================================
# 1. é…ç½®è·¯å¾„
# ==========================================
BASE_DATA_DIR = os.path.join(os.getcwd(), 'data') 

FILE_PATHS = {
    'options': os.path.join(BASE_DATA_DIR, 'IBIT_Active_Options.csv'),
    'spot': os.path.join(BASE_DATA_DIR, 'IBIT_Spot_Data.csv'), # <--- ä¿®æ­£ä¸º IBIT ç°è´§
    'dvol': os.path.join(BASE_DATA_DIR, 'DERIBIT_DVOL_1D.csv'),
    'rates': os.path.join(BASE_DATA_DIR, 'IRX_CACHE.csv')
}

def load_spot_data():
    """åŠ è½½ IBIT ç°è´§ä»·æ ¼"""
    try:
        print(f"   æ­£åœ¨è¯»å–ç°è´§æ•°æ®: {FILE_PATHS['spot']}")
        df = pd.read_csv(FILE_PATHS['spot'])
        
        # æ¸…æ´—æ—¥æœŸ
        df['Date'] = pd.to_datetime(df['Date']).dt.normalize()
        
        # ç¡®ä¿æŒ‰æ—¥æœŸæ’åº
        df = df.sort_values('Date')
        
        # å°† Date è®¾ä¸ºç´¢å¼•ï¼Œè¿”å› Spot_Close åˆ—
        # æ³¨æ„: IBIT æ•°æ®çš„åˆ—åé€šå¸¸æ˜¯ 'Spot_Close' æˆ– 'Close'
        col_name = 'Spot_Close' if 'Spot_Close' in df.columns else 'Close'
        return df.set_index('Date')[col_name]
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½ç°è´§æ•°æ®: {e}")
        return None

def process_chunk(chunk, spot_series):
    """å¤„ç†å•ä¸ªæ•°æ®å—"""
    # 1. æ—¥æœŸå¤„ç†
    chunk['Date'] = pd.to_datetime(chunk['Date']).dt.normalize()
    
    # 2. åŒ¹é…ç°è´§ä»·æ ¼ (åˆ©ç”¨ç´¢å¼•è‡ªåŠ¨å¯¹é½)
    if spot_series is not None:
        chunk['Spot'] = chunk['Date'].map(spot_series)
    else:
        chunk['Spot'] = np.nan

    # 3. è¿‡æ»¤æ— æ•ˆæ•°æ® (å¿…é¡»æœ‰ Spot æ‰èƒ½ç®— Moneyness)
    # å¹¶ä¸”åªçœ‹ 20-40 å¤©åˆ°æœŸçš„åˆçº¦ (æ¨¡æ‹Ÿ 30D ç­–ç•¥)
    # å…ˆè§£æ Expiration
    chunk['ExpirationStr'] = chunk['Symbol'].apply(lambda x: x.split('|')[1])
    chunk['Expiration'] = pd.to_datetime(chunk['ExpirationStr'], format='%Y%m%d')
    chunk['DTE'] = (chunk['Expiration'] - chunk['Date']).dt.days
    
    # ç­›é€‰æ¡ä»¶: 
    # 1. æœ‰ä»·æ ¼ (Bid/Ask/IV)
    # 2. æœ‰ç°è´§ä»·æ ¼ (Spot)
    # 3. DTE åœ¨ 20 åˆ° 40 å¤©ä¹‹é—´ (ä¸“æ³¨ 30D ç­–ç•¥çš„å‚æ•°æ ¡å‡†)
    valid_rows = chunk.dropna(subset=['Bid', 'Ask', 'ImpliedVolatility', 'Spot', 'Strike']).copy()
    valid_rows = valid_rows[(valid_rows['DTE'] >= 20) & (valid_rows['DTE'] <= 40)]
    
    if valid_rows.empty:
        return None

    # 4. è®¡ç®—æŒ‡æ ‡
    valid_rows['Mid'] = (valid_rows['Bid'] + valid_rows['Ask']) / 2
    # ç›¸å¯¹ä»·å·®
    valid_rows['Spread_Pct'] = (valid_rows['Ask'] - valid_rows['Bid']) / valid_rows['Mid']
    # è™šå€¼ç¨‹åº¦
    valid_rows['Moneyness'] = valid_rows['Strike'] / valid_rows['Spot']
    
    return valid_rows[['Date', 'OptionType', 'Moneyness', 'ImpliedVolatility', 'Spread_Pct']]

def calibrate_full_model():
    print(f"ğŸš€ å¼€å§‹å…¨é‡æ•°æ®æ ¡å‡† (Corrected Spot Source)...")
    
    # 1. å‡†å¤‡ç°è´§æ•°æ®
    spot_series = load_spot_data()
    if spot_series is None: return

    # 2. é€å—è¯»å–
    chunk_size = 100000 
    processed_chunks = []
    
    try:
        reader = pd.read_csv(FILE_PATHS['options'], iterator=True, chunksize=chunk_size)
        
        for i, chunk in enumerate(reader):
            print(f"   æ­£åœ¨å¤„ç†ç¬¬ {i+1} å—æ•°æ®...", end='\r')
            processed_df = process_chunk(chunk, spot_series)
            if processed_df is not None:
                processed_chunks.append(processed_df)
                
        print("\nâœ… æ•°æ®è¯»å–å®Œæˆï¼Œå¼€å§‹èšåˆåˆ†æ...")
        if not processed_chunks:
            print("âŒ è­¦å‘Šï¼šæ²¡æœ‰ç¬¦åˆæ¡ä»¶(20-40 DTE)çš„æ•°æ®ã€‚è¯·æ£€æŸ¥æ•°æ®æºæ—¥æœŸèŒƒå›´ã€‚")
            return

        df_all = pd.concat(processed_chunks, ignore_index=True)
        print(f"ğŸ“Š æœ‰æ•ˆæ ·æœ¬: {len(df_all)} è¡Œ")

        # 3. åˆ†æ¡¶ç»Ÿè®¡
        bins = [0.8, 0.9, 0.98, 1.02, 1.1, 1.2]
        labels = ['Deep Put (80-90%)', 'OTM Put (90-98%)', 'ATM (98-102%)', 'OTM Call (102-110%)', 'Deep Call (>110%)']
        df_all['Bucket'] = pd.cut(df_all['Moneyness'], bins=bins, labels=labels)
        
        summary = df_all.groupby(['Bucket', 'OptionType'])[['ImpliedVolatility', 'Spread_Pct']].mean()
        
        print("\n" + "="*60)
        print(" IBIT Options MicroStruc (30 DTE)")
        print("="*60)
        print(summary)
        print("="*60)

        # 4. æå–å‚æ•°
        print("\n [Calibration Parameters]")
        
        try:
            # 90% Put IV
            iv_put_90 = df_all[(df_all['Moneyness'] >= 0.88) & (df_all['Moneyness'] <= 0.92) & (df_all['OptionType']=='P')]['ImpliedVolatility'].mean()
            # ATM IV
            iv_atm = df_all[(df_all['Moneyness'] >= 0.98) & (df_all['Moneyness'] <= 1.02)]['ImpliedVolatility'].mean()
            
            skew_val = iv_put_90 - iv_atm
            print(f"1. Skew Bias (90% Put - ATM): {skew_val:.4f}")
        except:
            print("   (æ— æ³•è®¡ç®— Skew)")

        try:
            # ATM Spread
            spread_atm = df_all[(df_all['Moneyness'] >= 0.98) & (df_all['Moneyness'] <= 1.02)]['Spread_Pct'].mean()
            # OTM Put Spread
            spread_otm = df_all[(df_all['Moneyness'] >= 0.88) & (df_all['Moneyness'] <= 0.92) & (df_all['OptionType']=='P')]['Spread_Pct'].mean()
            
            print(f"2. Real Transaction Costs")
            print(f"   -> ATM Spread: {spread_atm:.2%}")
            print(f"   -> OTM Put Spread: {spread_otm:.2%}")
        except:
            print("   (æ— æ³•è®¡ç®— Spread)")
            
        # 5. DVOL å›å½’åˆ†æ (å¦‚æœéœ€è¦)
        # è¿™é‡Œéœ€è¦åŠ è½½ DVOL æ•°æ®å¹¶ mergeï¼Œå¦‚æœåªæ˜¯ä¸ºäº†è·å–å‡å€¼ï¼Œä¸Šé¢å·²ç»å¤Ÿäº†ã€‚
        # ä¸ºäº†ç®€å•èµ·è§ï¼Œè¿™é‡Œåªè¾“å‡ºå‡å€¼å‚æ•°ã€‚

    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    calibrate_full_model()